---
title: 秒杀系统
date: 2025-06-26 15:54:07
tags: 
  - Golang
  - 分布式
  - 高并发
  - 秒杀系统
top: 9
---

# 秒杀系统

## 简历描述

高并发秒杀系统 - Golang

- 设计并实现基于 Go、Kafka、Etcd 的高并发秒杀系统，涵盖抢购下单、库存扣减、异步落库、排行榜等核心功能，单节点 QPS 3000，支持 K8s 3 节点集群部署。  
- 使用 Etcd 实现强一致分布式锁，结合 WAL 持久化记录锁状态（UUID + LeaseID），实现锁的自动续租与服务重启恢复机制，避免锁丢失与惊群问题。  
- 引入令牌桶限流与 Kafka 异步下单机制，将秒杀高峰削峰至 1000 QPS，结合 Redis 缓存库存预热策略，在3节点环境下，1000 QPS 持续 30 秒压测，总请求中约 20% 出现 429 限流，总成功率达 70%。  
- 实现 Redis ZSet 异步排行榜同步机制，使用 Kafka + Goroutine 将高并发更新操作异步解耦，排行榜更新时间控制在 100ms 以内。  
- 部署 Prometheus 和 Grafana，监控库存命中率、限流 QPS、Kafka 消费延迟等关键指标，保障系统性能与稳定。

## 问题 第一行

> 设计并实现基于 Go、Kafka、Etcd 的高并发秒杀系统，涵盖抢购下单、库存扣减、异步落库、排行榜等核心功能，单节点 QPS 3000，支持 K8s 3 节点集群部署。

### **1. 秒杀系统整体架构是怎样的？各组件之间如何通信？**

**架构总览：**

- 整体分为：**网关层（限流）→ 秒杀服务（校验、锁、库存）→ 消息队列（Kafka）→ 异步落库服务 → 排行榜同步服务**；
- 各模块通过 HTTP/gRPC + Kafka 实现异步解耦；
- 读操作走 Redis 缓存，写操作通过 Kafka 异步落库，最终一致性。

**通信流程简述：**

1. 用户发起秒杀请求，经网关限流（令牌桶）后到达 `seckill-service`；
2. `seckill-service` 检查库存缓存 → 加 Etcd 锁 → 原子扣减 Redis 库存；
3. 请求成功后写入 Kafka（下单 Topic）；
4. `order-consumer` 消费消息并写入 MySQL；
5. 同时 Kafka 另一路消息用于排行榜异步更新（ZSet）；
6. 所有模块接入 Prometheus，暴露 `/metrics` 端点用于监控。

### **2. 令牌桶算法是什么，解决什么问题，具体数值设置为多少**

**原理简述：**

- 令牌桶是流控算法之一，系统按固定速率生成令牌，请求必须获取令牌才被处理，超限请求被拒绝（返回 429）；
- 相比漏桶能容忍短期突发流量（令牌可以累积）；

**在本项目中：**

- 每个商品设置 1000 QPS 的令牌速率（`rate = 1000/s`），桶容量为 1000；
- 使用 Redis + Lua 实现共享限流器，支持多副本共享状态；
- 限流控制入口在网关或服务中间件（Gin 中间件）；

**解决的问题：**

- 避免瞬时流量压垮下游系统（Redis、MySQL）；
- 提升服务稳定性，使后端服务处理能力与流量强度解耦。

### **3. 单节点 QPS 3000 是如何测试的？测试工具和环境如何配置？**

- 使用k6进行压力测试，配置了 1000 个虚拟用户并发请求，最大尝试每秒 3000 次请求，持续 30 秒。测试环境为单节点部署，docker-compose 启动 Golang 服务，加上健康检查，Kafka 和 Etcd 也在同一节点上运行。
- 单节点，i5-12600KF, 32GB DDR4 6000MHz；接口为本地网关直连（无 CDN、无反向代理），实际上线运行时为防止下游写压力，设置削峰限流至 1000 QPS。

### **4. Kafka 在系统中的作用具体是什么？为什么不用 RabbitMQ？**

核心解耦组件：

- 接收异步下单消息；
- 分发排行榜更新事件；
- 实现削峰填谷，防止高并发直接写数据库；（**削峰**：在流量高峰期，通过**限流、排队、异步处理**等方式，减少瞬时请求量，防止系统过载；**填谷**：在流量低谷期，利用系统空闲资源处理积压的请求，避免资源浪费。）

选择Kafka的原因:

- 吞吐高，消息积压容忍度高
- **持久化存储默认使用WAL，高可用**
- **分区有序适合订单类场景**，RabbitMQ无强顺序保证
- Go有sarama库支持

### **5. Etcd 主要做什么？为什么不选 Redis 实现锁？**

etcd的作用：

- 提供 **CP（强一致）分布式锁服务**；
- 使用 `Put + Lease + Compare` 保证锁唯一性与可恢复性；
- 锁内容包含 UUID、商品 ID、租约 ID，配合 WAL 落盘支持自动恢复；
- 避免惊群与锁漂移问题。

> **惊群问题**
>
> **问题描述**
>
> 当多个客户端同时竞争同一把锁时，如果锁释放，所有等待的客户端会**同时被唤醒**，并疯狂重试抢锁，导致：
>
> - **大量无效请求**：只有一个客户端能成功，其余请求被拒绝，造成资源浪费。
> - **网络和 CPU 压力激增**：高并发场景下可能压垮服务端。
>
> **etcd 的解决方案**
>
> etcd 通过 **`Lease`（租约） + `Watch` 机制** 避免惊群：
>
> 1. **客户端抢锁失败后**，不会轮询查询，而是通过 `Watch` 监听锁的释放事件。
> 2. **锁释放时**，etcd 只会通知一个等待的客户端（按 FIFO 或公平调度），其他客户端继续等待。
>
> **对比 Redis 的缺陷**：
> Redis 的锁（如 Redlock）在释放时，所有客户端会**立即重试抢锁**，容易引发惊群效应。

| 点       | Etcd             | Redis            |
| -------- | ---------------- | ---------------- |
| 一致性   | CP 保证强一致    | AP，有主从延迟   |
| 锁续约   | 有 Lease 机制    | 需手动设置过期   |
| 健康检查 | 原生绑定客户端   | 需额外处理心跳   |
| 自动恢复 | Lease+WAL 可恢复 | 崩溃后锁状态丢失 |

### **6. 3 节点 K8s 部署是多台物理机还是单机模拟？调度策略怎么做的？**

- **多台物理机**，每台机器运行一个 K8s 节点，使用 kubeadm 部署；
- **调度策略**：使用 K8s 的默认调度器，Pod 分布在 3 个节点上，保证高可用；
- **Pod 副本数**：每个服务（如 `seckill-service`、`order-consumer`）设置为 3 副本，确保负载均衡和容错；
- **服务发现**：使用 K8s 内置的 DNS 服务，Pod 通过服务名访问；
- **健康检查**：配置 Liveness 和 Readiness 探针，确保 Pod 健康状态，自动重启不健康的 Pod。
- **资源限制**：每个 Pod 设置 CPU 和内存限制，防止单个 Pod 占用过多资源影响其他服务。

### **7. 下单、扣库存、落库、排行榜之间是串行的还是异步解耦的？**

- **下单**：用户请求到达 `seckill-service`，先进行限流和库存检查；
- **扣库存**：通过 Etcd 分布式锁保证同一商品的并发请求串行处理，避免超卖；
- **落库**：下单成功后，将订单信息写入 Kafka，异步消费落库；
- **排行榜**：使用 Kafka 异步更新排行榜，`order-consumer` 消费订单消息后更新 Redis ZSet。
- **异步解耦**：下单、扣库存、落库、排行榜更新之间通过 Kafka 实现异步解耦，避免直接依赖，提高系统吞吐量。

### **8. 高并发下如何避免超卖和重复下单？**

- **超卖**：使用 Etcd 分布式锁，确保同一商品的并发请求串行处理，锁粒度为商品 ID；
- **重复下单**：每个订单生成唯一 ID（如 UUID），在下单前检查 Redis 缓存中是否已存在该订单 ID；
  - 如果存在，直接返回已下单响应；
  - 如果不存在，继续处理下单逻辑；
- **幂等性**：下单接口设计为幂等，确保同一请求多次发送不会导致重复扣减库存或重复下单；
- **Redis 缓存**：使用 Redis 缓存订单状态，快速判断是否已下单，避免重复请求。
- **数据库唯一索引**：在 MySQL 中对订单 ID 设置唯一索引，防止重复插入。
- **乐观锁**：在扣减库存时使用乐观锁（如 `UPDATE ... WHERE stock = stock - 1`），确保库存正确。
- **事务处理**：在 MySQL 中使用事务，确保下单、扣减库存、写入订单等操作要么全部成功，要么全部回滚，避免数据不一致。
- **限流**：使用令牌桶限流，控制每秒请求数，防止瞬时高并发导致超卖。

### **9. 如何做多副本部署时的服务注册与发现？**

- **服务注册**：使用 K8s 的内置服务发现机制，Pod 启动时自动注册到 K8s DNS；
- **服务发现**：其他服务通过 K8s 服务名访问，如 `seckill-service`，K8s DNS 会自动解析到对应的 Pod IP；
- **负载均衡**：K8s 内置的负载均衡器会将请求分发到不同的 Pod 副本上，保证流量均匀分布；
- **健康检查**：配置 Liveness 和 Readiness 探针，确保只有健康的 Pod 接受请求，自动剔除不健康的 Pod；
- **配置管理**：使用 ConfigMap 和 Secret 管理配置和敏感信息，Pod 启动时自动加载；
- **滚动更新**：使用 K8s 的滚动更新策略，确保服务升级时不中断服务，逐个替换 Pod 副本，保持高可用。


## 问题 第二行

> 使用 Etcd 实现强一致分布式锁，结合 WAL 持久化记录锁状态（UUID + LeaseID），实现锁的自动续租与服务重启恢复机制，避免锁丢失与惊群问题。

### **为什么选用 Etcd 做分布式锁，而不是 Redis？**

- Etcd 提供 CP（强一致性）模型，适合需要强一致性的分布式锁场景；
- Redis 是 AP（可用性优先），在网络分区或主从延迟时可能导致锁状态不一致；
- Etcd 的 `Lease` 机制支持自动续租，避免锁过期导致的丢失；
- Etcd 的 `Compare-And-Swap` 操作可以确保锁的唯一性和原子性；
- Etcd 的 `Watch` 机制可以监听锁状态变化，避免惊群问题。

### **你是如何使用 LeaseID 做自动续租的？是否会续租失败？**

- 使用`Grant`方法创建租约，指定租约 TTL（如 60 秒）；
- 在获取锁时，将租约 ID 绑定到锁的 key 上；
- 启动一个协程定期调用 `KeepAliveOnce` 方法续租，确保锁在 TTL 内不会过期；
- 如果续租失败（如 Etcd 集群不可用），会记录日志并尝试重新获取锁；
- 如果服务重启，Etcd 会自动恢复锁状态，只要租约未过期，锁仍然有效。

```golang
// Etcd 锁续租示例
leaseResp, err := cli.Grant(ctx, leaseTTL) // 创建租约
if err != nil {
    return err
}
_, err = cli.Put(ctx, lockKey, lockValue, clientv3.WithLease(leaseResp.ID)) // 设置锁
if err != nil {
    return err
}
// 启动续租协程
go func() {
    ticker := time.NewTicker(renewInterval)
    defer ticker.Stop()
    for {
        select {
        case <-ticker.C:
            _, err := cli.KeepAliveOnce(ctx, leaseResp.ID) // 续租
            if err != nil {
                log.Printf("续租失败: %v", err)
                return
            }
        case <-ctx.Done():
            return
        }
    }
}()
```

### **什么是 WAL（Write-Ahead Log）？你怎么实现落盘和恢复的？**

- **WAL（Write-Ahead Log）**：写前日志，是一种持久化机制，确保数据在内存操作前先写入日志，保证数据一致性和可靠性；
- 在 Etcd 中，WAL 用于记录所有写操作（如锁的获取和释放），即使服务崩溃也能恢复锁状态；
- **实现步骤**：
  1. 在获取锁时，将锁状态（如 UUID、LeaseID）写入 WAL；
  2. 使用 Etcd 的 `Put` 操作将锁状态存储在 Etcd 中；
  3. 服务重启时，读取 WAL 日志，恢复锁状态；
  4. 如果租约未过期，继续使用原有锁状态，否则重新获取锁。
  5. WAL 日志通常存储在 Etcd 的数据目录中，Etcd 会自动管理日志的回收和清理。
  6. Etcd 的 WAL 机制保证了即使在网络分区或节点故障时，锁状态也不会丢失。

### **如果服务意外崩溃，如何保证锁的状态不会丢失？**

### **什么是惊群问题？Etcd 如何避免？**

### **你们有没有考虑锁饥饿、死锁的情况？**

### **Lease 到期前锁失效怎么办？是否会误删其他节点的锁？**

## 问题 第三行

> 引入令牌桶限流与 Kafka 异步下单机制，将秒杀高峰削峰至 1000 QPS，结合 Redis 缓存库存预热策略，在 3 节点环境下，1000 QPS 持续 30 秒压测，总请求中约 20% 出现 429 限流，总成功率达 70%。

### **为什么用令牌桶限流而不是漏桶？限流粒度是 IP 级还是全局？**

### **你是如何设置令牌生成速率和桶容量的？**

### **Kafka 下单异步流程怎么保证消息不丢？用了哪些配置？**

### **Redis 缓存库存是怎么预热的？预热策略是什么？怎么回源？**

### **为什么 429 限流率这么高？是否考虑更细化限流策略？**

### **成功率 70% 是针对所有请求吗？剩下 30% 是失败还是限流？**

### **压测用的是什么工具？并发模型是怎样的？**

### **如果 Kafka 消费延迟了，会导致库存错误吗？如何避免重复消费？**

### **如何保证 Kafka 消息幂等？是否使用了唯一 ID 或幂等键？**

## 问题 第四行

> 实现 Redis ZSet 异步排行榜同步机制，使用 Kafka + Goroutine 将高并发更新操作异步解耦，排行榜更新时间控制在 100ms 以内。

### **排行榜的业务目的是什么？展示什么指标？**

### **为什么使用 Redis ZSet？ZSet 是怎么构造 key 和 score 的？**

### **异步同步具体是怎么做的？Kafka 消息如何转成 ZSet 操作？**

### **Kafka 消费慢了怎么办？是否有批量处理优化？**

### **排行榜更新频率高怎么做并发控制？**

### **为什么控制在 100ms 以内？这个数据怎么测出来的？**

### **Redis 高并发写入是否考虑分片或持久化压力？**

## 问题 第五行

> 部署 Prometheus 和 Grafana，监控库存命中率、限流 QPS、Kafka 消费延迟等关键指标，保障系统性能与稳定。

### **用的哪些指标做系统监控？Prometheus 是如何采集这些指标的？**

### **限流 QPS 如何暴露为指标？是通过 middleware 中间件采集的吗？**

### **Kafka 消费延迟是怎么算的？是消费时间减生产时间吗？**

### **库存命中率是如何定义和记录的？从 Redis 采集吗？**

### **有设置告警吗？什么阈值下触发告警？**

### **Grafana 展示的关键仪表盘有哪些？**

### **是否有做分布式链路追踪（如 Jaeger）？对定位性能瓶颈是否有帮助？**
